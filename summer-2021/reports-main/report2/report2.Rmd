---
title: "An Analysis of The Use of Force by U.S. Law Enforcement Agencies"
subtitle: "Summer 2022 Research: Report 2"
author: "Sajid Bin Mahamud"
header-includes:
    - \usepackage{setspace}
output:
  bookdown::pdf_document2: 
    number_sections: true
    toc: true
  bookdown::html_notebook2: 
    number_sections: true
urlcolor: blue 
bibliography: references.bib
nocite: '@*'
csl: apa.csl
link-citations: yes
linkcolor: blue
---

```{r settings, echo=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(kableExtra)
library(tidyverse)
library(kableExtra)
library(fbi) 
library(tidyverse)
library(lubridate)

```


```{r dataCleaning, echo=FALSE, include=FALSE, warning=FALSE}

### to abstain from confusing department names
### need to replace department with ORI code
### identify which department codes are missing 
### from data from before 2022 (we don't want to work on 2022, 
### because it might provide an incomplete picture)

mpvData <- 
  read_csv("~/police-violence-study/reports/report2/mpv.csv")

# stage one data is filtered out data from before 2022
mpvData <- 
  mpvData %>% filter(year <= 2021)

# identifying which row doesn't have a police department listed 
mpvData[which(is.na(mpvData$ori)),]

# will fill in missing data for agencies via excel 

##stage two data is filtered out 

```


```{r fbiData, echo=FALSE, include=FALSE, warning=FALSE}

## Uncomment the following two lines of code.
## Run them once and comment it back.
# install.packages("devtools")
# devtools::install_github("jacobkap/fbi")

API_KEY = "UQdRQU5cN0hitFUs5BNelClg2OS6Vywd5jqPEqaa"
set_api_key(API_KEY)

#which agencies reported in 2012
#Agency_2012 <- agencies_2000_2020 %>% filter(data_year == 2012)

#which department had officers killed in the line of duty

##get rid of departments which didn't report data
#stageOne <- leoka_monthly_2012 %>% 
 # filter(covered_by == "no, it is not covered by another agency") %>% 
 # select(ori9, number_of_months_reported, month, date, 
        # fips_state_county_code, fips_place_code, 
        # msa, covered_by, month_indicator, covered_by, record_indicator, 
        # report_indicator, )




```

```{r pilot run, echo=FALSE, include=FALSE, warning=FALSE}

# Loading data ----
# the data contains new york's leoka reports (assaults and killed LEO) from 2012 to 2017
# I started from 2012 because we have civilian death record of MPV from 2013
# I felt at least starting a year earlier should be useful, 
# but we could also start from way earlier but the data, I feel, becomes less reliable as we go back in time. 
# but overall, a Bayesian analysis should be able to utilize more data to better the approximate 

NY12 <- leoka_monthly_2012 %>% 
  filter(state_abb == "NY")
NY13 <- leoka_monthly_2013 %>% 
  filter(state_abb == "NY")
NY14 <- leoka_monthly_2014 %>% 
  filter(state_abb == "NY")
NY15 <- leoka_monthly_2015 %>% 
  filter(state_abb == "NY")
NY16 <- leoka_monthly_2016 %>% 
  filter(state_abb == "NY")
NY17 <- leoka_monthly_2017 %>% 
  filter(state_abb == "NY")

leokaNY12_17 <- rbind(NY12, NY13, NY14, NY15, NY16, NY17)

# making the month column and formatting date as date ----

leokaNY12_17$month = month(as.POSIXlt(leokaNY12_17$date, format = "%Y-%m-%d"))
leokaNY12_17$date = date(as.POSIXlt(leokaNY12_17$date, format = "%Y-%m-%d"))

# to isolate agencies that have reported all months of reports ----
# selecting variables of interest and renaming ori codes

INTleokaNY12_17 <- leokaNY12_17 %>% 
  filter(number_of_months_reported ==12) %>% 
  rename(legacy_ori = ori, ori = ori9) %>% 
  select(ori, month, year, date,
         officers_killed_by_felony,
         assaults_with_injury_total, 
         assaults_no_injury_total) 
  

# load data on civilian deaths ----
# limit to data from 2013 to 2017 for manageability 
# select variables of interest
# group in order to create summaries

psNY13_17 <- mpvData %>% filter(state == "NY") %>%
  filter(year == 2013 |
           year == 2014 | 
           year == 2015 | 
           year == 2016 | 
           year == 2017) %>% 
  select(ori, name, date, month, year) %>%
  group_by(year, month, ori)


# make table of months when departments killed and did not kill people ----
# i added date 15 because its the middle of the months 
# then turn the characters into date format

psNY13_17list$month_Year = 
  paste("15", "-", psNY13_17list$month, "-", psNY13_17list$year)
psNY13_17list$month_Year = 
  date(as.POSIXlt(psNY13_17list$month_Year, format = "%d - %m - %Y"))

# create a dummy data frame
# the purpose of doing this is to create monthly chart of all the 
# departments and their civilian deaths 

test <- psNY13_17list %>%  
  pivot_wider(id_cols = !month:year, 
              names_from = month_Year, 
              values_from = `killed per agency per month per year`, 
              values_fill = 0)

# hehe, fooled you, i tidy my data
test <- test %>% 
  pivot_longer(cols = !ori, names_to = "Month-Year", 
               values_to = "Killed per agencty-month-year")

#see when people in NY were killed and temporarily remove the cases where more than one agency was involved ----
psNY13_17list <- psNY13_17 %>% 
  filter(nchar(ori) == 9) %>% 
  mutate(`killed per agency per month per year` = n()) %>%
  select(ori, month, year,`killed per agency per month per year`) %>% 
  unique()

# plot the time series ----

ggplot(psNY13_17list, aes(x = date,
                          y = `killed per agency per month per year`)) +
  geom_point(aes(color = ori)) + 
  scale_x_date(date_breaks = "1 month", 
               date_labels = "%m %y") +
  theme(axis.text.x = element_text(angle = 90, 
                                   vjust = 0.5, hjust=1))

# take the departments from the psNYlist to grab violent crime rates, attack on LEO, LEO kills etc ----
# for LEO kills, need to consult somebody to know what to do bc 1. 
# not a lot of LEO are killed and 2. unreliable assault data


psNY13_17listMerged <- merge(psNY13_17list, INTleokaNY12_17, by = "year", "month", "ori")


```

# Study Design 

## Data Cleaning

The Law Enforcement Officer Killed and Assaulted (LEOKA) data set reports monthly data in several categories including Law Enforcement Officer (LEO) killed feloniously, LEO assaulted with and without injury. Amongst the agencies that submit data, some agencies do not submit their own data, instead they do it through some other agency. Moreover, among those who submit data, some agencies do not submit data for all months. Therefore the \textbf{first stage} 

### Incidents Involving Multiple Agencies

Since a primary ambition of the analysis is to understand \textbf{how aggression or hostility against LEOs affect the use of force by LEOs acoross agencies.} A key factor of my initial assumption is that felonious death of LEO doesn't only affect the agency involved but may also influence neighboring agencies. Hence, when a killed suspect (KS) who involves multiple departments doesn't clearly tell us which agency was influenced how much by the recent events. However, if we look at a cluster of departments then it could be easier to identify effect of assault and killing on policing practices. 

## Is the data reliable?

I don't believe so. The reasons are very well evident in the patterns of reporting. The reporting of assault increases over time. So it creates some skepticism over the validity of the data in measuring overall effects. 

# Interest population 

## LEOKA

* Departments which reported all 12 months. From the analysis, exclude departments which didn't report for all 12 months and departments which didn't report at all. 

## Civilian deaths

* Exclude incidents where multiple agencies were involved because it doesn't strictly indicate intent. 

## Justifiable vs Unjustifiable

Different states have different defining criteria for use of force. 

A big part of the conversation is to understand how and when to use force in order to escape punishment under state law. 




@Montiel2021


```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}

```